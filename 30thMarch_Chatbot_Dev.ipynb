{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fe32e0dff44c468b9aeb2f48ba0798ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FileUploadModel",
          "model_module_version": "1.5.0",
          "state": {
            "_counter": 2,
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FileUploadModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FileUploadView",
            "accept": ".pdf,.html,.txt",
            "button_style": "",
            "data": [
              null
            ],
            "description": "Upload",
            "description_tooltip": null,
            "disabled": false,
            "error": "",
            "icon": "upload",
            "layout": "IPY_MODEL_6ab841e9d97a464c9c343f8206201819",
            "metadata": [
              {
                "name": "GRPC.pdf",
                "type": "application/pdf",
                "size": 2965435,
                "lastModified": 1675218908121
              }
            ],
            "multiple": false,
            "style": "IPY_MODEL_c0a088f9aac94924a0158248ec33d8a5"
          }
        },
        "6ab841e9d97a464c9c343f8206201819": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0a088f9aac94924a0158248ec33d8a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "e9c578efea2648259f3bd7b9d643394c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_0cc34faf0f204d51a824ddd09ee85d88",
            "placeholder": "Ask your question here...",
            "style": "IPY_MODEL_c3c8f6296a8a4450b15adba0a87fc1b1",
            "value": ""
          }
        },
        "0cc34faf0f204d51a824ddd09ee85d88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3c8f6296a8a4450b15adba0a87fc1b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4a2f8ce03924340ad7fe6547ff9d28c": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_e2d3dcd7772f4bd98fe482e0c7023737",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "User: \"What is the main context of the file\"\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "PrivateAI:  a n d  T C P  p o r t s .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P C  c a n  n o t  b e  u s e d .  I f  t h e  f i r e w a l l  i s  c l o s e d  t o  t h e  p o r t s  t h a t  g R P C  u s e s ,  t h e n  g R P\n"
                ]
              }
            ]
          }
        },
        "e2d3dcd7772f4bd98fe482e0c7023737": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **How to create a chatbot with Private Knowledge-base with RAG**"
      ],
      "metadata": {
        "id": "cxO_VUaSeyF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **What is it?**\n",
        "\n",
        "* **The chatbot can answer question related a particular document, specific business, product or domain**\n",
        "\n",
        "* **Unlike GPT, a personal chatbot is trained using RAG**"
      ],
      "metadata": {
        "id": "SfZOIm6he723"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **How this thing can be done**\n",
        "\n",
        "* **The user should be allowed to upload a document**\n",
        "  * **System should be able to read the document**\n",
        "-----------------------\n",
        "* **Stem and Split all the data**\n",
        "* **Each chink will converted to numerical representation**"
      ],
      "metadata": {
        "id": "g1xAZxXQfNYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POqI44Znf3mh",
        "outputId": "f420a73d-e7ca-43cc-e825-a4508c5a4d5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nltk\n",
        "from PyPDF2 import PdfReader\n",
        "from bs4 import BeautifulSoup as bs\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "id": "145JlzKFdPND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt\")\n",
        "\n",
        "nltk.download(\"punkt_tab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMV6YJsnf_RW",
        "outputId": "87b7ca0b-fbef-41e5-fcbd-d2da4a2f89cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "segments_SIZE = 99999\n",
        "NUMBER_OF_MATCHES = 3"
      ],
      "metadata": {
        "id": "7Z8qwfI6g8Y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ps = PorterStemmer()"
      ],
      "metadata": {
        "id": "-Kb2ZWjEgbNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **This function will help us pre-process**"
      ],
      "metadata": {
        "id": "6BOKo6YbgfVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_text(txt, segments_size = segments_SIZE):\n",
        "  sentences = sent_tokenize(txt)\n",
        "\n",
        "  # TI s\n",
        "  original_text = []\n",
        "  processed_text = []\n",
        "  segments = \"\"\n",
        "\n",
        "# If the len of current Seg with len of current state is greater than decided chunk size\n",
        "  for x in sentences:\n",
        "    if len(segments) + len(x) >segments_size:\n",
        "      original_text.append(segments)\n",
        "      processed_text.append(\" \".join([ps.stem(word) for word in segments.split()]))\n",
        "      segments = x\n",
        "    else:\n",
        "      segments += \" \" + x\n",
        "  # This is for handling the last piece of text / segment\n",
        "  if segments:\n",
        "    original_text.append(segments)\n",
        "    processed_text.append(\" \".join([ps.stem(word) for word in segments.split()]))\n",
        "\n",
        "  return original_text, processed_text"
      ],
      "metadata": {
        "id": "KBVlFo91geF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load the PDF**"
      ],
      "metadata": {
        "id": "x0Idcb7zjTvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_pdf(file_path):\n",
        "  with open(file_path, \"rb\") as file:\n",
        "    reader = PdfReader(file)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "      text += page.extract_text()\n",
        "  return process_text(text)"
      ],
      "metadata": {
        "id": "N2-3U3Lfin5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Read the HTML**"
      ],
      "metadata": {
        "id": "UNeyh-ZPjs7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_HTML(file_path):\n",
        "  with open(file_path, \"r\") as file:\n",
        "    soupFile = bs(file, \"html.parser\")\n",
        "    text = soupFile.get_text()\n",
        "    return process_text(text)"
      ],
      "metadata": {
        "id": "NsThOHJQjqxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Read the Text File**"
      ],
      "metadata": {
        "id": "Sox5HwEdkYIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_text(file_path):\n",
        "  with open(file_path, \"r\") as file:\n",
        "    text = file.read()\n",
        "    return process_text(text)"
      ],
      "metadata": {
        "id": "EBwCzajTkJt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Processing the Content**"
      ],
      "metadata": {
        "id": "JSO8t01PkomT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Finding the best matches (similarity)**"
      ],
      "metadata": {
        "id": "R45JTYUvkzrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "7moYMSGRklUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()"
      ],
      "metadata": {
        "id": "Fzb-3nKtlDZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = []\n",
        "\n",
        "original_docs = []\n",
        "\n",
        "vectors = None"
      ],
      "metadata": {
        "id": "U51myMKzlGed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_document(text):\n",
        "  documents.extend(text)\n",
        "  vectors = vectorizer.fit_transform(documents)\n",
        "  return vectors"
      ],
      "metadata": {
        "id": "YdCLGTeSl7TI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_and_add_document(file_path, file_type):\n",
        "  if file_type == \"pdf\":\n",
        "    original_data, processed_text = read_pdf(file_path=file_path)\n",
        "  elif file_type == \"html\":\n",
        "    original_data, processed_text = read_HTML(file_path=file_path)\n",
        "  elif file_type == \"text\":\n",
        "    original_data, processed_text = read_text(file_path=file_path)\n",
        "  else:\n",
        "    raise ValueError(\"Unsupported File Format recieved! Please pass relevant File format!!\")\n",
        "\n",
        "  original_docs.extend(original_data) # All the original data segment will be stored here\n",
        "  vectors = add_document(processed_text)\n",
        "  return vectors"
      ],
      "metadata": {
        "id": "SXhPS0U-lLbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_matches(query, top_n = NUMBER_OF_MATCHES):\n",
        "  query_processed = process_text(query)[1]\n",
        "  query_vector = vectorizer.transform(query_processed)\n",
        "  similarity = (query_vector * vectors.T).toarray()\n",
        "\n",
        "  best_match_indexes = similarity.argsort()[0][-top_n:][::-1]\n",
        "\n",
        "  return [original_docs[i] for i in best_match_indexes], [documents[i] for i in best_match_indexes]"
      ],
      "metadata": {
        "id": "809xIpgamQkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Constructing the Prompt for LLM**"
      ],
      "metadata": {
        "id": "rRJFyucFsLbq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Engineering a Prompt**"
      ],
      "metadata": {
        "id": "RVOlm2U9saBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cohere"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpOQZZkGtM1N",
        "outputId": "1d4acf9d-145e-4409-d7e2-63bdd5af22a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cohere in /usr/local/lib/python3.11/dist-packages (5.14.0)\n",
            "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in /usr/local/lib/python3.11/dist-packages (from cohere) (1.10.0)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.28.1)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.4.0)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.10.6)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.27.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.21.1)\n",
            "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.32.0.20250328)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<1,>=0.15->cohere) (0.29.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.67.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cohere\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "SKhACJm8nQlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "co = cohere.ClientV2(api_key=userdata.get(\"CohereKey\"))"
      ],
      "metadata": {
        "id": "rOZulASgse1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_resp(query, context):\n",
        "  messages = [\n",
        "      {\"role\": \"system\", \"content\": \"You are a AI assistant. Use the provided context to answer the user's query accurately and precisely. Try to keep answer concise.\"},\n",
        "      {\"role\" : \"system\", \"content\": context},\n",
        "      {\"role\":\"user\", \"content\": query}\n",
        "  ]\n",
        "\n",
        "  response = co.chat(\n",
        "    model=\"command-r-plus-08-2024\",\n",
        "    messages = messages\n",
        "  )\n",
        "\n",
        "  return response.message.content[0].text.strip()"
      ],
      "metadata": {
        "id": "EzO4Ev0FtuoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Put all this together**"
      ],
      "metadata": {
        "id": "GY0_wXb0u0Ud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reset_database():\n",
        "  global documents, original_docs, vectors\n",
        "  documents = []\n",
        "  original_docs = []\n",
        "  vectors = None"
      ],
      "metadata": {
        "id": "7rywJjqjuZzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize(file_name):\n",
        "  file_type = file_name.split(\".\")[-1]\n",
        "  return process_and_add_document(file_path=file_name, file_type=file_type)"
      ],
      "metadata": {
        "id": "wzzW488ou-gv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(user_query, is_debug = False):\n",
        "  original_best_docs_match, processed_doc_match = find_best_matches(user_query)\n",
        "  context = \"\\n\\n\".join(original_best_docs_match)\n",
        "\n",
        "  if is_debug:\n",
        "    print(f\"Context: {context}\")\n",
        "  resp = get_resp(user_query, context)\n",
        "  return resp"
      ],
      "metadata": {
        "id": "OLllZ-X6vBfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Test**"
      ],
      "metadata": {
        "id": "DyDnWyB2wkGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "def download_files():\n",
        "  samples_files = [\n",
        "      {\n",
        "          \"url\" : \"https://www.ipcc.ch/report/ar6/wg1/downloads/outreach/IPCC_AR6_WGI_SummaryForAll.pdf\",\n",
        "          \"file_name\":\"climateChange.pdf\"\n",
        "      },\n",
        "      {\n",
        "          \"url\":\"https://medium.com/illumination/i-tried-10-decaf-coffees-as-a-first-time-coffee-drinker-heres-what-i-found-a8c5fb93a40e\",\n",
        "          \"file_name\": \"coffee.html\"\n",
        "      }\n",
        "  ]\n",
        "\n",
        "  for x in samples_files:\n",
        "    resp = requests.get(x[\"url\"])\n",
        "    with open(x[\"file_name\"] ,\"wb\") as f:\n",
        "      f.write(resp.content)\n",
        "\n",
        "  return [files[\"file_name\"] for files in samples_files]"
      ],
      "metadata": {
        "id": "geW4o0z8wjoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files_names = download_files()\n",
        "\n",
        "for file_name in files_names:\n",
        "  print(file_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "326oXlJnw9SS",
        "outputId": "e1e329df-f5f8-4d28-9c97-ebc9043ff231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "climateChange.pdf\n",
            "coffee.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reset_database()"
      ],
      "metadata": {
        "id": "QxVdZfeNxlBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectors = initialize(\"climateChange.pdf\")"
      ],
      "metadata": {
        "id": "sR4rwT2bxtvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resp = chat(\"Who are the authors of the report\")"
      ],
      "metadata": {
        "id": "zx7X6kqax_w8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(resp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zguDSK-yHMh",
        "outputId": "bf8b43e6-936b-4b2b-8f8e-9813d624abae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The report is written by members of the Working Group I Technical Support Unit (WGI TSU) and several authors of the report. The authors are:\n",
            "\n",
            "- Sarah Connors (WGI TSU)\n",
            "- Sophie Berger (WGI TSU)\n",
            "- Clotilde Péan (WGI TSU)\n",
            "- Govindasamy Bala (Chapter 4 author)\n",
            "- Nada Caud (WGI TSU)\n",
            "- Deliang Chen (Chapter 1 author)\n",
            "- Tamsin Edwards (Chapter 9 author)\n",
            "- Sandro Fuzzi (Chapter 6 author)\n",
            "- Thian Yew Gan (Chapter 8 author)\n",
            "- Melissa Gomis (WGI TSU)\n",
            "- Ed Hawkins (Chapter 1 author)\n",
            "- Richard Jones (Atlas Chapter author)\n",
            "- Robert Kopp (Chapter 9 author)\n",
            "- Katherine Leitzell (WGI TSU)\n",
            "- Elisabeth Lonnoy (WGI TSU)\n",
            "- Douglas Maraun (Chapter 10 author)\n",
            "- Valérie Masson-Delmotte (WGI Co-Chair)\n",
            "- Tom Maycock (WGI TSU)\n",
            "- Anna Pirani (WGI TSU)\n",
            "- Roshanka Ranasinghe (Chapter 12 author)\n",
            "- Joeri Rogelj (Chapter 5 author)\n",
            "- Alex C. Ruane (Chapter 12 author)\n",
            "- Sophie Szopa (Chapter 6 author)\n",
            "- Panmao Zhai (WGI Co-Chair)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reset_database()\n",
        "vectors = initialize(\"coffee.html\")\n",
        "\n",
        "while True:\n",
        "  user_query = input(\"Hi, Please ask! (type 'quit' or 'exit' to stop): \")\n",
        "  if user_query.lower() in [\"quit\", \"exit\"]:\n",
        "    print(\"Thanks, Hope it helped you!. (PrivateAI left the conversation)..\")\n",
        "    break\n",
        "\n",
        "  print(\"========================================\")\n",
        "  print(f\"User: \\\"{user_query}\\\"\")\n",
        "  resp = chat(user_query)\n",
        "  print(\"PrivateAI: \", resp, flush = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDfyNz9iyKGd",
        "outputId": "673c44f9-1d3f-4ef5-e04b-c815b7877391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi, Please ask! (type 'quit' or 'exit' to stop): What is main idea in the document\n",
            "========================================\n",
            "User: \"What is main idea in the document\"\n",
            "PrivateAI:  The author, Kory Becker, shares their experience as a first-time coffee drinker, trying out 10 different decaf coffee brands. They provide a personal review of these coffees based on taste, experience, and price, offering insights into their preferences as a newcomer to the world of coffee.\n",
            "Hi, Please ask! (type 'quit' or 'exit' to stop): Who is author\n",
            "========================================\n",
            "User: \"Who is author\"\n",
            "PrivateAI:  The author of the article is Kory Becker.\n",
            "Hi, Please ask! (type 'quit' or 'exit' to stop): quit\n",
            "Thanks, Hope it helped you!. (PrivateAI left the conversation)..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Create a interface that help to upload file and then start the conversation with chatbot\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "# ... (Your existing code) ...\n",
        "\n",
        "# Create file upload widget\n",
        "uploader = widgets.FileUpload(\n",
        "    accept='.pdf,.html,.txt',  # Accept PDF, HTML, and text files\n",
        "    multiple=False  # Allow only one file at a time\n",
        ")\n",
        "\n",
        "# Create text input widget for user queries\n",
        "text_input = widgets.Text(placeholder='Ask your question here...')\n",
        "\n",
        "# Create output widget to display chatbot responses\n",
        "output = widgets.Output()\n",
        "\n",
        "# Function to handle file upload\n",
        "def on_file_upload(change):\n",
        "  with output:\n",
        "    clear_output()  # Clear previous output\n",
        "    uploaded_file = list(change['new'].values())[0]\n",
        "    file_name = uploaded_file['metadata']['name']\n",
        "    with open(file_name, 'wb') as f:\n",
        "      f.write(uploaded_file['content'])\n",
        "\n",
        "    try:\n",
        "      global vectors\n",
        "      reset_database()\n",
        "      vectors = initialize(file_name)\n",
        "      print(f\"File '{file_name}' uploaded successfully.\")\n",
        "      print(\"Ready for your questions!\")\n",
        "    except Exception as e:\n",
        "      print(f\"Error processing the uploaded file: {e}\")\n",
        "\n",
        "\n",
        "# Function to handle user queries\n",
        "def on_submit(change):\n",
        "  with output:\n",
        "    clear_output(wait=True)  # Clear output and wait for new output\n",
        "    user_query = text_input.value\n",
        "    text_input.value = ''  # Clear the input field after submission\n",
        "\n",
        "    if user_query.lower() in [\"quit\", \"exit\"]:\n",
        "      print(\"Thanks, Hope it helped you!. (PrivateAI left the conversation)..\")\n",
        "      return\n",
        "\n",
        "    print(f\"User: \\\"{user_query}\\\"\")\n",
        "    resp = chat(user_query)\n",
        "    print(\"PrivateAI: \", resp, flush=True)\n",
        "\n",
        "# Attach event handlers\n",
        "uploader.observe(on_file_upload, names='value')\n",
        "text_input.on_submit(on_submit)\n",
        "\n",
        "# Display the widgets\n",
        "display(uploader)\n",
        "display(text_input)\n",
        "display(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810,
          "referenced_widgets": [
            "fe32e0dff44c468b9aeb2f48ba0798ab",
            "6ab841e9d97a464c9c343f8206201819",
            "c0a088f9aac94924a0158248ec33d8a5",
            "e9c578efea2648259f3bd7b9d643394c",
            "0cc34faf0f204d51a824ddd09ee85d88",
            "c3c8f6296a8a4450b15adba0a87fc1b1",
            "c4a2f8ce03924340ad7fe6547ff9d28c",
            "e2d3dcd7772f4bd98fe482e0c7023737"
          ]
        },
        "id": "Rm1l24CAzKdF",
        "outputId": "fed32084-ffe0-451b-be0b-4be55c39e03e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FileUpload(value={}, accept='.pdf,.html,.txt', description='Upload')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe32e0dff44c468b9aeb2f48ba0798ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Text(value='', placeholder='Ask your question here...')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9c578efea2648259f3bd7b9d643394c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4a2f8ce03924340ad7fe6547ff9d28c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoQLl6Lc0tIb",
        "outputId": "f4702a17-fe33-442e-e5c9-11717a7425ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.23.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio)\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.29.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.23.1-py3-none-any.whl (51.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading ruff-0.11.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.1-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: aiofiles\n",
            "    Found existing installation: aiofiles 24.1.0\n",
            "    Uninstalling aiofiles-24.1.0:\n",
            "      Successfully uninstalled aiofiles-24.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "unstructured-client 0.32.0 requires aiofiles>=24.1.0, but you have aiofiles 23.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.23.1 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 ruff-0.11.2 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.1 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Assuming reset_database(), initialize(file_path), chat(query) are defined elsewhere\n",
        "\n",
        "def process_file_and_chat(file_obj, query):\n",
        "    if file_obj is None:\n",
        "        return \"Please upload a file first.\", \"\"\n",
        "\n",
        "    file_path = file_obj.name\n",
        "    try:\n",
        "        reset_database()\n",
        "        initialize(file_path)\n",
        "        response = chat(query)\n",
        "        return \"File processed. Ready for questions!\", response\n",
        "    except Exception as e:\n",
        "        return f\"Error processing file: {e}\", \"\"\n",
        "\n",
        "def respond(message, chat_history):\n",
        "    bot_message = chat(message)\n",
        "    chat_history.append((message, bot_message))\n",
        "    return \"\", chat_history\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# File Upload and Chatbot Interface\")\n",
        "    with gr.Row():\n",
        "        file_input = gr.File(label=\"Upload File\", file_types=[\".pdf\", \".html\", \".txt\"])\n",
        "        text_input = gr.Textbox(label=\"Enter your question\")\n",
        "    process_button = gr.Button(\"Process File and Start Chat\")\n",
        "    output_message = gr.Textbox(label=\"Status\")\n",
        "    chatbot = gr.Chatbot(label=\"Chatbot\")\n",
        "    clear = gr.ClearButton([text_input, chatbot])\n",
        "\n",
        "    process_button.click(\n",
        "        fn=process_file_and_chat,\n",
        "        inputs=[file_input, text_input],\n",
        "        outputs=[output_message, chatbot]\n",
        "    )\n",
        "\n",
        "    text_input.submit(respond, [text_input, chatbot], [text_input, chatbot])\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "t7RfL_eb0A6F",
        "outputId": "9c0e648d-135c-4803-9424-74b91127e0ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-7d21e0137d2d>:30: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(label=\"Chatbot\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://146e28f722bbb37fea.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://146e28f722bbb37fea.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qv6Tu84X0uqs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}